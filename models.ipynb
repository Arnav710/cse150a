{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "SEED = 0\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/preprocessed-ai-medical-chatbot.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:1020\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "df.sample(5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train, test, and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['description', 'question'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m X_train_and_val, X_test, y_train_and_val, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[1;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['description', 'question'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[['description', 'question']]\n",
    "y = df['answer']\n",
    "\n",
    "X_train_and_val, X_test, y_train_and_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_and_val, y_train_and_val, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train set: 208097\n",
      "Number of samples in validation set: 23122\n",
      "Number of samples in test set: 25691\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples in train set: {X_train.shape[0]}\")\n",
    "print(f\"Number of samples in validation set: {X_val.shape[0]}\")\n",
    "print(f\"Number of samples in test set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model based on Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class ProbabilityBasedAgent:\n",
    "    \n",
    "\tdef __init__(self, questions, responses):\n",
    "\t\tself.questions = questions\n",
    "\t\tself.responses = responses\n",
    "\t\tself.question_sets = []\n",
    "\t\tself.vocab = None\n",
    "\n",
    "\tdef get_vocab(self):\n",
    "\t\tvocab = set()\n",
    "\t\tfor question in self.questions:\n",
    "\t\t\tfor word in question.split():\n",
    "\t\t\t\tvocab.add(word)\n",
    "\t\treturn list(vocab)\n",
    "\n",
    "\tdef prob_query_given_sentence(self, query, sentence_lst, alpha=1):\n",
    "\t\tquery_lst = query.split()\n",
    "\t\tmatch = 0\n",
    "\t\t\n",
    "\t\tfor token in query_lst:\n",
    "\t\t\tif token in sentence_lst:\n",
    "\t\t\t\tmatch += 1\n",
    "\t\t\n",
    "\t\t# Apply Laplace smoothing\n",
    "\t\tnumerator = match + alpha\n",
    "\t\tdenominator = len(query_lst) + alpha\n",
    "\t\t\n",
    "\t\tp = numerator / denominator\n",
    "\t\treturn p\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.vocab = self.get_vocab()\n",
    "\n",
    "\t\tfor question in self.questions:\n",
    "\t\t\tself.question_sets.append(set(question.split()))\n",
    "\n",
    "\tdef find_closest_answer(self, query, k):\n",
    "\t\t\n",
    "\t\tprobabilities_match = []\n",
    "\t\tfor i in range(len(self.questions)):\n",
    "\t\t\tprob = self.prob_query_given_sentence(query, self.question_sets[i])\n",
    "\t\t\tprobabilities_match.append((prob, self.questions[i], self.responses[i]))\n",
    "\n",
    "\t\tprobabilities_match.sort(reverse=True)\n",
    "\n",
    "\t\treturn probabilities_match[:k]\n",
    "\n",
    "# Constrain size of train data to 20000 cause of compute restriction\t\n",
    "training_questions = list(X_train['description'])[:20000]\n",
    "training_responses = list(y_train)[:20000]\n",
    "\n",
    "# Constrain size of train data to 20000 cause of compute restriction\t\n",
    "training_questions = list(X_train['description'])[:20000]\n",
    "training_responses = list(y_train)[:20000]\n",
    "\n",
    "model = ProbabilityBasedAgent(training_questions, training_responses)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are some of the closest responses we could find:\n",
      "Probability: 0.2222222222222222\n",
      "Question: x ray result back indicate\n",
      "Answer: hi showing loss of curvature and straightening of spine in elderly might be due to degenerative and osteo artheritis in spines but as you are young this might be due to faulty posture of sitting this can be due to long time sitting in front of computer or table work correct your posture sit straight and avoid bending from back while doing work go for back extension exercises daily ok and take care \n",
      "\n",
      "Probability: 0.2222222222222222\n",
      "Question: would painless lump back\n",
      "Answer: hi   good evening  i am dr shareef answering your query  although a personal physical examination of the lump would be helpful in reaching a nearby diagnosis  most probably with a history of trauma  it could be an organised hematoma on the left side of your back  to confirm the diagnosis  if i were your doctor  i would go for an fnac  fine needle aspiration cytology  followed possibly by an excision biopsy depending on the report of the fnac   considering the duration of more than 4 years  clinically it might be a benign lesion not to worry about  however  for cosmetic reasons it might be required to be taken out therefore  i would advise you to consult a general surgeon and get your self assessed for the same i hope this information would help you in discussing with your family physician treating doctor in further management of your problem  please do not hesitate to ask in case of any further doubts thanks for choosing health care magic to clear doubts on your health problems  wishing you an early recovery  dr shareef \n",
      "\n",
      "Probability: 0.2222222222222222\n",
      "Question: worried strong back pain falling back\n",
      "Answer: hi  thanks for using hcm in my opinion you should stop worrying  for immediate relief have some pain killer along with a muscle relaxant and have proper bed rest for few days  do not lie down on soft mattress use hard one instead  do not strain your self or over exert  u can also apply some good anti inflammatory pain killer gel on your back  if the pain increases do some hot fermentation locally\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I have back pain, what should i do?\"\n",
    "responses = model.find_closest_answer(user_query, 3)\n",
    "\n",
    "print(\"The following are some of the closest responses we could find:\")\n",
    "\n",
    "for sim, q, a in responses:\n",
    "    \n",
    "\tprint(f\"Probability: {sim}\")\n",
    "\tprint(f\"Question: {q}\")\n",
    "\tprint(f\"Answer: {a}\")\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(preds, y):\n",
    "    def overlap(pred, answer):\n",
    "        pred_words = set(pred.lower().split())\n",
    "        answer_words = set(answer.lower().split())\n",
    "        overlap = pred_words.intersection(answer_words)\n",
    "        return len(overlap) / len(answer_words) if answer_words else 0\n",
    "\n",
    "    scores = [overlap(pred, answer) for pred, answer in zip(preds, y)]\n",
    "    scores.sort()\n",
    "    return scores[len(scores) // 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a subsample of 25 for testing due to compute constraints\n",
    "preds = []\n",
    "sample = 25\n",
    "for x in X_test['description'][:sample]:\n",
    "    sim, q, a = model.find_closest_answer(x, 1)[0]\n",
    "    preds.append(a)\n",
    "y = y_test[:sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22535211267605634\n"
     ]
    }
   ],
   "source": [
    "print(eval_fn(preds, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a subsample of 25 from training due to compute constraints\n",
    "preds = []\n",
    "sample = 25\n",
    "for x in X_train['description'][:sample]:\n",
    "    sim, q, a = model.find_closest_answer(x, 1)[0]\n",
    "    preds.append(a)\n",
    "y = y_train[:sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(eval_fn(preds, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Model Based On Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def cosine_similarity(user, ques):\n",
    "    dot_product = sum(x*y for x, y in zip(user, ques))\n",
    "    magnitude_user = sum(x*x for x in user)**0.5\n",
    "    magnitude_ques = sum(y*y for y in ques)**0.5\n",
    "    return dot_product / (magnitude_user * magnitude_ques)\n",
    "\n",
    "\n",
    "class SimilarityBasedAgent:\n",
    "    \n",
    "\tdef __init__(self, questions, responses):\n",
    "\t\tself.questions = questions\n",
    "\t\tself.responses = responses\n",
    "\t\tself.vocab = None\n",
    "\t\tself.questions_vectors = None\n",
    "\n",
    "\tdef get_vocab(self):\n",
    "\t\tvocab = set()\n",
    "\t\tfor question in self.questions:\n",
    "\t\t\tfor word in question.split():\n",
    "\t\t\t\tvocab.add(word)\n",
    "\t\treturn list(vocab)\n",
    "\t\n",
    "\tdef bag_of_words(self, question):\n",
    "\t\tvec = []\n",
    "\t\tfor token in self.vocab:\n",
    "\t\t\tvec.append(question.count(token))\n",
    "\t\treturn vec\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tself.vocab = self.get_vocab()\n",
    "\t\tvectors = []\n",
    "\t\tfor question in self.questions:\n",
    "\t\t\tvectors.append(self.bag_of_words(question))\n",
    "\t\tself.questions_vectors = vectors\n",
    "\n",
    "\tdef find_closest_answer(self, query, k):\n",
    "\t\tuser_query_vector = self.bag_of_words(query)\n",
    "\t\t\n",
    "\t\tsimilarities = []\n",
    "\t\tfor i in range(len(self.questions)):\n",
    "\t\t\tsim = cosine_similarity(user_query_vector, self.questions_vectors[i])\n",
    "\t\t\tsimilarities.append((sim, self.questions[i], self.responses[i]))\n",
    "\n",
    "\t\tsimilarities.sort(reverse=True)\n",
    "\n",
    "\t\treturn similarities[:k]\n",
    "\n",
    "# Constrain size of train data to 20000 cause of compute restriction\t\n",
    "training_questions = list(X_train['description'])[:20000]\n",
    "training_responses = list(y_train)[:20000]\n",
    "\n",
    "model = SimilarityBasedAgent(training_questions, training_responses)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are some of the closest responses we could find:\n",
      "Similarity: 0.7456785876210714\n",
      "Question: causes sharp pain shoulders back neck thighs\n",
      "Answer: hello and welcome to  ask a doctor  service i have reviewed your query and here is my advice in my opinion  the symptoms point towards disc prolapse which needs to be evaluated with x ray and mri  hope i have answered your query  let me know if i can assist you further regards  dr  fahim sheik\n",
      "\n",
      "Similarity: 0.7172191381865586\n",
      "Question: causes sharp shooting pain back head\n",
      "Answer: hi thanks for writing in to us there are many causes of a shooting pain in the back of the head  commonly a neuralgia of the trigeminal nerve can cause such a condition  it has branches which supplies the back of the head  this can trigger sharp pains to the area  however a clinical examination is required to confirm the condition other causes of such pains can be from nerve pinching in the cervical spine  the nerves leave the spinal cord through small foramina and if there is cervical spine disc disease then the nerves are under pressure and can cause a sensation of sharp pain in the back of the head and neck regions pain below the ear can also happen due to inflammation of blood vessels called arteritis  usually temporal arteritis is a common cause of pain on the side of head and around the ear  please consult a neurologist for confirmation  please do not worry \n",
      "\n",
      "Similarity: 0.7128451081042417\n",
      "Question: whats causing back pain stomach pain radiating buttocks thigh 2 years healed back injury\n",
      "Answer: hithank for asking to hcmi can understand your worry and i could say that this is not because of your injury but this could be dysmenorrhea  refer pain of this could be toward your buttock and thigh and this will go way with the help of any pain killer and the drug of choice would be   ibuprofen   you can try this  nothing to worry about this  this is not the big problem will go away soon  take care and have nice day \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_query = \"I have back pain, what should i do?\"\n",
    "responses = model.find_closest_answer(user_query, 3)\n",
    "\n",
    "print(\"The following are some of the closest responses we could find:\")\n",
    "\n",
    "for sim, q, a in responses:\n",
    "    \n",
    "\tprint(f\"Similarity: {sim}\")\n",
    "\tprint(f\"Question: {q}\")\n",
    "\tprint(f\"Answer: {a}\")\n",
    "\tprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a subsample of 25 for testing due to compute constraints\n",
    "preds = []\n",
    "sample = 25\n",
    "for x in X_test['description'][:sample]:\n",
    "    sim, q, a = model.find_closest_answer(x, 1)[0]\n",
    "    preds.append(a)\n",
    "y = y_test[:sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(eval_fn(preds, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a subsample of 25 from training due to compute constraints\n",
    "preds = []\n",
    "sample = 25\n",
    "for x in X_train['description'][:sample]:\n",
    "    sim, q, a = model.find_closest_answer(x, 1)[0]\n",
    "    preds.append(a)\n",
    "y = y_train[:sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y = y_train[:sample]\n",
    "\n",
    "print(eval_fn(preds, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
